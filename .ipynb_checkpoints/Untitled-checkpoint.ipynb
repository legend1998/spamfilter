{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries required\n",
    "\"\"\" \n",
    "pandas - for dataframe,\n",
    "numpy - creating array and manipulation\n",
    "nltk.tokenize for tokenization \n",
    "math - for log10 \n",
    "string for punctuation \n",
    "matplotlib - for ploting graph\n",
    "sklearn = to calcalulate accuracy of prediction or classifier\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import math\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "read the datafile as csv format\n",
    "\"\"\"\n",
    "\n",
    "dataset = pd.read_csv(\"hns_2018_2019.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset according as 2018 year as training dataset\n",
    "# nad 2019 year as testing dataset\n",
    "\n",
    "training_set=dataset.loc[dataset['year']==2018,['Title','year','Post Type']]\n",
    "\n",
    "testing_set=dataset.loc[dataset['year']==2019,['Title','year','Post Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after that we will use training dataset to create model \n",
    "\"\"\"\n",
    "steps for creating model \n",
    "\n",
    "    1. categorised title according to post type so we have three category story, ask_hn,show_hn\n",
    "    2. for each category tokenize each to its corresponding category and also calculate frequency of each word\n",
    "    \n",
    "    after step 1 and 2 we have all words with category and frequncy in its coresponding category\n",
    "    \n",
    "    now we will make vocabulary by merging all words and calculating frequncy of each word\n",
    "    \n",
    "    after that we have vocabulary as \n",
    "    \n",
    "    word          story     ask-hn       show-hn\n",
    "    \n",
    "    terminal        12        5             0\n",
    "    the             232       234          23\n",
    "\n",
    "\n",
    "    3. after getting vocabualry we will compute p(wi/post_type) for each word in vocabulary \n",
    "    \n",
    "        and this data will merge with vocabulary called model and save as 2018-model.txt\n",
    "    \n",
    "\"\"\"\n",
    "#we have three category story ask-hn and show-hn so all title wiil divide in three coresponding category\n",
    "\n",
    "story=training_set.loc[training_set['Post Type']=='story',['Title']]\n",
    "ask_hn=training_set.loc[training_set['Post Type']=='ask_hn',['Title']]\n",
    "show_hn=training_set.loc[training_set['Post Type']=='show_hn',['Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize each title of story and store each word in vb_of_story \n",
    "#and its frequency will be stored in fr_of_sotry\n",
    "\n",
    "vb_of_story=[]\n",
    "fr_of_story=[]\n",
    "\n",
    "for word in story['Title']:\n",
    "    word=word.lower()\n",
    "    word=word_tokenize(word)\n",
    "    for token in word:\n",
    "        if token in string.punctuation:\n",
    "            continue\n",
    "        if (token not in vb_of_story):\n",
    "            vb_of_story.append(token)\n",
    "            fr_of_story.append(1)\n",
    "        else:\n",
    "            fr_of_story[vb_of_story.index(token)]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same will perform with ask_hn as well as show_Hn\n",
    "\n",
    "vb_of_show_hn=[]\n",
    "fr_of_show_hn=[]\n",
    "\n",
    "for word in show_hn['Title']:\n",
    "    word=word.lower()\n",
    "    word=word_tokenize(word)\n",
    "    for token in word:\n",
    "        if token in string.punctuation:\n",
    "            continue\n",
    "        if token not in vb_of_show_hn:\n",
    "            vb_of_show_hn.append(token)\n",
    "            fr_of_show_hn.append(1)\n",
    "        else:\n",
    "            fr_of_show_hn[vb_of_show_hn.index(token)]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb_of_ask_hn=[]\n",
    "fr_of_ask_hn=[]\n",
    "\n",
    "for word in ask_hn['Title']:\n",
    "    word=word.lower()\n",
    "    word=word_tokenize(word)\n",
    "    for token in word:\n",
    "        if token in string.punctuation:\n",
    "            continue\n",
    "\n",
    "        if token not in vb_of_ask_hn:\n",
    "            vb_of_ask_hn.append(token)\n",
    "            fr_of_ask_hn.append(1)\n",
    "        else:\n",
    "            fr_of_ask_hn[vb_of_ask_hn.index(token)]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we calculate each word's frequncy in all categpry and store it in vb \n",
    "# and its frequency into fr        \n",
    "\n",
    "vb=[]\n",
    "fr=[]\n",
    "\n",
    "for word in training_set['Title']:\n",
    "    word=word.lower()\n",
    "    word=word_tokenize(word)\n",
    "    for token in word:\n",
    "        if token in string.punctuation:\n",
    "            continue\n",
    "        if token not in vb:\n",
    "            vb.append(token)\n",
    "            fr.append(1)\n",
    "        else:\n",
    "            fr[vb.index(token)]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we calcualte number of words belongs post \n",
    "story=np.zeros(len(vb),dtype=int)\n",
    "ask_hn=np.zeros(len(vb),dtype=int)\n",
    "show_hn=np.zeros(len(vb),dtype=int)\n",
    "poll=np.zeros(len(vb),dtype=int)\n",
    "\n",
    "\n",
    "for word in vb:\n",
    "    if word in vb_of_story:\n",
    "        story[vb.index(word)]+= fr_of_story[vb_of_story.index(word)]\n",
    "    if word in vb_of_ask_hn:\n",
    "        ask_hn[vb.index(word)]+=fr_of_ask_hn[vb_of_ask_hn.index(word)]\n",
    "    if word in vb_of_show_hn:\n",
    "        show_hn[vb.index(word)]+=fr_of_show_hn[vb_of_show_hn.index(word)]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after calcaulating each word's frequency into all post_type we will\n",
    "#put all this information at one place called vocabualry using pandas dataframe\n",
    "        \n",
    "vocabulary = pd.DataFrame({\n",
    "        \"word\":vb,\n",
    "        \"story\":story,\n",
    "        \"ask_hn\":ask_hn,\n",
    "        \"show_hn\":show_hn,\n",
    "        \"poll\":poll,\n",
    "        \"frequency\":fr},index=vb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will calculate post_type probability for each post\n",
    "\"\"\"\n",
    "   as total number of post is 5000 \n",
    "   p(story)= number of story/(total)\n",
    "   p(ask_hn)=number of ask_Hn/total\n",
    "   p(show_hn)=number of show_hn/total\n",
    "   \n",
    "\"\"\"\n",
    "post_type = training_set['Post Type'].value_counts()\n",
    "prob_set=pd.DataFrame({\n",
    "        \"story\":post_type[0]/5000,\n",
    "        \"ask_hn\":post_type[1]/5000,\n",
    "        \"show_hn\":post_type[2]/5000},index=[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are defining a function named sm)cnd_pro which calcualtes \n",
    "#    smoothed conditional probability for given word and post\n",
    "#   it takes wi = number of in the post \n",
    "#           post = total no of word in post\n",
    "# and round it to 6 decimal    \n",
    "    \n",
    "    \n",
    "def sm_cnd_pro(wi,post):\n",
    "    smooth=0.5\n",
    "    wi+=smooth\n",
    "    return round((wi/post),6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each word word in vocabulary we calculate smoothed conditional probabli;ity\n",
    "# for each post\n",
    "\n",
    "cnd_prob_story=[]\n",
    "cnd_prob_ask_hn=[]\n",
    "cnd_prob_show_hn=[]\n",
    "cnd_prob_poll=[]\n",
    "\n",
    "for word in vb:\n",
    "    index=vb.index(word)\n",
    "    cnd_prob_story.append(sm_cnd_pro(story[index],post_type[0]))\n",
    "\n",
    "for word in vb:\n",
    "    index=vb.index(word)\n",
    "    cnd_prob_ask_hn.append(sm_cnd_pro(ask_hn[index],post_type[1]))\n",
    "\n",
    "for word in vb:\n",
    "    index=vb.index(word)\n",
    "    cnd_prob_show_hn.append(sm_cnd_pro(show_hn[index],post_type[2]))\n",
    "    \n",
    "for word in vb:\n",
    "    cnd_prob_poll.append(-99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# after calculating smoothed conditional probablility we meerge this with vocabulary\n",
    "\n",
    "vocabulary[\"cnd_prob_story\"]=cnd_prob_story\n",
    "vocabulary[\"cnd_prob_ask_hn\"]=cnd_prob_ask_hn\n",
    "vocabulary[\"cnd_prob_show_hn\"]=cnd_prob_show_hn\n",
    "vocabulary[\"cnd_prob_poll\"]=cnd_prob_poll\n",
    "#now we have model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write vocabulary to into text file named vocabulary.txt\n",
    "\n",
    "file=open('vocabulary.txt','w+',encoding=\"utf-8\")\n",
    "vocabulary=vocabulary.sort_values('word')\n",
    "for word in vocabulary.index:\n",
    "    file.write(word)\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcition to write model into text file\n",
    "\n",
    "\n",
    "def write_model(vocabulary,name):\n",
    "    file=open(name,'w+',encoding=\"utf-8\")\n",
    "    n=1\n",
    "    for word in vocabulary.index:\n",
    "        curr=vocabulary.loc[word]\n",
    "        \n",
    "        file.write(str(n)+\"  \")\n",
    "        file.write(str(word)+\"  \")\n",
    "        file.write(str(int(curr['story']))+\"  \")\n",
    "        file.write(str(curr['cnd_prob_story'])+'  ')\n",
    "        file.write(str(int(curr['ask_hn']))+'  ')\n",
    "        file.write(str(curr['cnd_prob_ask_hn'])+'  ')\n",
    "        file.write(str(int(curr['show_hn']))+'  ')\n",
    "        file.write(str(curr['cnd_prob_show_hn'])+'  ')\n",
    "        file.write(str(int(curr['poll']))+'  ')\n",
    "        file.write(str(curr['cnd_prob_poll'])+'\\n')\n",
    "        n+=1\n",
    "    file.close()\n",
    "\n",
    "#write model to text file \n",
    "write_model(vocabulary,'model-2018.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will make classifier which calcaulates probability of each post with aords\n",
    "# it returns reulsts which contains actual post type with prediced post_type\n",
    "def classifier(vocabulary):    \n",
    "    pre_class={0:'story',1:'ask_hn',2:'show_hn'}\n",
    "    \n",
    "    score=[]\n",
    "    predicted=[]\n",
    "    for post in testing_set['Title']:\n",
    "        post = post.lower()\n",
    "        post=word_tokenize(post)\n",
    "        class_prob=[round(math.log10(prb),4) for prb in prob_set.iloc[0]]\n",
    "        for word in post:\n",
    "            if word in string.punctuation:\n",
    "                continue\n",
    "            if word in vocabulary.index:\n",
    "                row=vocabulary[vocabulary.index==word]\n",
    "                class_prob[0]+=math.log10(row['cnd_prob_story'])\n",
    "                class_prob[1]+=math.log10(row['cnd_prob_ask_hn'])\n",
    "                class_prob[2]+=math.log10(row['cnd_prob_show_hn'])\n",
    "        score.append(class_prob)\n",
    "        predicted.append(pre_class[class_prob.index(max(class_prob))])\n",
    "        \n",
    "    \n",
    "    result =pd.DataFrame({\n",
    "            'Title':testing_set['Title'],\n",
    "            'actual':testing_set['Post Type'],\n",
    "            'predicted':predicted,\n",
    "            'score':score})\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the classifier with giving model and sotre it in result\n",
    "\n",
    "\n",
    "result=classifier(vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 205    0    0]\n",
      " [   1  150    0]\n",
      " [1729 1148 1767]]\n",
      "0.4244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       0.11      1.00      0.19       205\n",
      "     show_hn       0.12      0.99      0.21       151\n",
      "       story       1.00      0.38      0.55      4644\n",
      "\n",
      "    accuracy                           0.42      5000\n",
      "   macro avg       0.41      0.79      0.32      5000\n",
      "weighted avg       0.94      0.42      0.53      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the result by accuracy and confuasion matrix and classification repsot\n",
    "print(confusion_matrix(result['actual'],result['predicted']))\n",
    "print(accuracy_score(result['actual'],result['predicted']))\n",
    "print(classification_report(result['actual'],result['predicted']))\n",
    "\n",
    "# here baseline accuracy is 42.44% \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  write_result is function which will write result ot text file\n",
    "\n",
    "def write_result(result,name):\n",
    "    file=open(name,'w+',encoding='utf8')\n",
    "    n=1\n",
    "    for row in result.index:\n",
    "        doc=result.loc[row]\n",
    "        file.write(str(n)+\"  \")\n",
    "        file.write(str(doc['Title'][0:15] )+ \"..  \")\n",
    "        file.write(str(doc['predicted'])+\"  \")\n",
    "        file.write(str(doc['score'][0])+\"  \")\n",
    "        file.write(str(doc['score'][1])+\"  \")\n",
    "        file.write(str(doc['score'][2])+\"  \")\n",
    "        file.write(str(doc['actual'])+\"  \")\n",
    "        file.write(str('right' if doc['predicted']==doc['actual'] else 'wrong')+\"\\n\")\n",
    "        n+=1\n",
    "    file.close()\n",
    "write_result(result,'baseline-result.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#task 3.1\n",
    "# store all words in stopwords.txt and then drop all stopwords from vocabualry or model\n",
    "\n",
    "file=open('stopwords.txt','r+',encoding='utf-8')\n",
    "stopwords=[word.replace('\\n','') for word in file if word.replace('\\n','') in vocabulary.index]\n",
    "file.close()\n",
    "stop_words_vcb=vocabulary.drop(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the classifier \n",
    "result=classifier(stop_words_vcb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 205    0    0]\n",
      " [   0  151    0]\n",
      " [1253 1497 1894]]\n",
      "0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       0.14      1.00      0.25       205\n",
      "     show_hn       0.09      1.00      0.17       151\n",
      "       story       1.00      0.41      0.58      4644\n",
      "\n",
      "    accuracy                           0.45      5000\n",
      "   macro avg       0.41      0.80      0.33      5000\n",
      "weighted avg       0.94      0.45      0.55      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy\n",
    "print(confusion_matrix(result['actual'],result['predicted']))\n",
    "print(accuracy_score(result['actual'],result['predicted']))\n",
    "print(classification_report(result['actual'],result['predicted']))\n",
    "\n",
    "# accuracy is 45%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after succesfull write vocabulary into textfile named stopw_words.txt and \n",
    "# result to stop_words_result.txt\n",
    "\n",
    "write_model(stop_words_vcb,' stopword-model.txt')\n",
    "write_result(result,'stopword-result.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 3.2\n",
    "\n",
    "#drop all the words as task 3.2 told\n",
    "dropped=[word for word in vocabulary.index if len(word)<=2 or len(word)>=9]\n",
    "vocabulary2=vocabulary.drop(dropped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the classifier and write to wordlength_model.text\n",
    "# and wordlength_results.txt\n",
    "result=classifier(vocabulary2)\n",
    "write_model(stop_words_vcb,' wordlength-model.txt')\n",
    "write_result(result,'wordlength-result.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 205    0    0]\n",
      " [   2  149    0]\n",
      " [1384  970 2290]]\n",
      "0.5288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ask_hn       0.13      1.00      0.23       205\n",
      "     show_hn       0.13      0.99      0.23       151\n",
      "       story       1.00      0.49      0.66      4644\n",
      "\n",
      "    accuracy                           0.53      5000\n",
      "   macro avg       0.42      0.83      0.37      5000\n",
      "weighted avg       0.94      0.53      0.63      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# chech the result\n",
    "print(confusion_matrix(result['actual'],result['predicted']))\n",
    "print(accuracy_score(result['actual'],result['predicted']))\n",
    "print(classification_report(result['actual'],result['predicted']))\n",
    "\n",
    "# accuracy is 52.8%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 1.3\n",
    "\n",
    "#gradually drop words which have frequency less than 5, 10, 15 and 20 and calculate word left with performance\n",
    "\n",
    "words_left=[]\n",
    "performance=[]\n",
    "ran=[5,10,15,20]\n",
    "for r in ran:\n",
    "    dropped=[word for word in vocabulary2.index if vocabulary2.loc[word]['frequency']<=r]\n",
    "    vocabulary2=vocabulary2.drop(dropped)\n",
    "    result=classifier(vocabulary2)\n",
    "    words_left.append(len(vocabulary2))\n",
    "    performance.append(accuracy_score(result['actual'],result['predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#gradually drop the top 5%. 10% , 15% , 20% and 25% frequncy word and calculate\n",
    "# and calcualte words_left vs performance \n",
    "    \n",
    "\n",
    "ran=[5,10,15,20,25]\n",
    "for r in ran:\n",
    "    vocabulary2=vocabulary2.sort_values('frequency', ascending=False)\n",
    "    dropped=[word for word in vocabulary2.head(r).index]\n",
    "    vocabulary3=vocabulary2.drop(dropped)\n",
    "    result=classifier(vocabulary3)\n",
    "    words_left.append(len(vocabulary3))\n",
    "    performance.append(accuracy_score(result['actual'],result['predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the graph word_left vs performance\n",
    "\n",
    "plt.scatter(words_left,performance)\n",
    "plt.xlabel(\"words left\")\n",
    "plt.ylabel(\"performance\")\n",
    "plt.title(\"words left vs performance\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
